{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1c733c45"
   },
   "source": [
    "# **FINAL CM GROUP 7**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a924a0c0"
   },
   "source": [
    "## **[1] Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25bfca36"
   },
   "source": [
    "### **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kmo8xGQiEqqs"
   },
   "outputs": [],
   "source": [
    "!pip install mediapipe\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MediaPipe for face detection\n",
    "import mediapipe as mp\n",
    "\n",
    "# Scikit-learn for ML pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Scikit-image for LBP\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"MediaPipe version: {mp.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88d77ae1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDSTyht9FEm4"
   },
   "source": [
    "### **Project Configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYDtNp9sh9RI"
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'DATASET_SOURCES': {\n",
    "        'masked': Path('/content/drive/MyDrive/Campus/PCVK_5/IMAGES/PBL/PRIMARY/MASKED'),\n",
    "        'unmasked': Path('/content/drive/MyDrive/Campus/PCVK_5/IMAGES/PBL/PRIMARY/UNMASKED'),\n",
    "    },\n",
    "    'DATASET_LIMIT': 100,\n",
    "    'USE_BOTH_SOURCES': True,\n",
    "    'MODEL_PATH': Path('models'),\n",
    "    'FACE_DETECTION_CONFIDENCE': 0.5,\n",
    "    'EYE_ROI_TARGET_SIZE': (96, 32),\n",
    "    'NEIGHBORS': 12,\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "CONFIG['MODEL_PATH'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Eye landmark indices\n",
    "LEFT_EYE_INDICES = [33, 133, 160, 159, 158, 157, 173]  # Left eye contour\n",
    "RIGHT_EYE_INDICES = [362, 263, 387, 386, 385, 384, 398]  # Right eye contour\n",
    "\n",
    "FACE_OVAL_INDICES = [\n",
    "    10, 338, 297, 332, 284, 251, 389, 356, 454,\n",
    "    323, 361, 288, 397, 365, 379, 378, 400, 377,\n",
    "    152, 148, 176, 149, 150, 136, 172, 58, 132,\n",
    "    93, 234, 127, 162, 21, 54, 103, 67, 109\n",
    "]\n",
    "\n",
    "\n",
    "# Initialize MediaPipe Face Mesh (global)\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=CONFIG['FACE_DETECTION_CONFIDENCE']\n",
    ")\n",
    "\n",
    "print(\"✓ Configuration loaded!\")\n",
    "print(f\"Dataset sources:\")\n",
    "for name, path in CONFIG['DATASET_SOURCES'].items():\n",
    "    print(f\"  {name}: {path}\")\n",
    "print(f\"Use both sources: {CONFIG['USE_BOTH_SOURCES']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SUvpYuDFPHR"
   },
   "source": [
    "### **Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7shWp80FTpi"
   },
   "outputs": [],
   "source": [
    "def log(msg):\n",
    "    \"\"\"\n",
    "    Fungsi untuk menampilkan pesan log dengan timestamp\n",
    "\n",
    "    Parameter:\n",
    "        msg: Pesan yang akan ditampilkan\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(f\"[{timestamp}] {msg}\")\n",
    "\n",
    "print(\"✓ Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXyZaZgAFcz1"
   },
   "source": [
    "## **[2] Loading Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bq5WwqaBF2a6"
   },
   "outputs": [],
   "source": [
    "def load_dataset(dataset_sources, use_both=True, limit=50):\n",
    "    \"\"\"\n",
    "    Memuat dataset gambar dari folder yang telah ditentukan\n",
    "\n",
    "    Parameter:\n",
    "        dataset_sources: Dictionary berisi path ke folder masked dan unmasked\n",
    "        use_both: Boolean untuk menggunakan kedua sumber data (masked & unmasked)\n",
    "        limit: Jumlah maksimal gambar per folder (default: 50)\n",
    "\n",
    "    Return:\n",
    "        all_image_paths: List berisi path semua gambar\n",
    "        all_labels: List berisi label ID untuk setiap gambar\n",
    "        label_to_id: Dictionary mapping nama orang ke ID numerik\n",
    "    \"\"\"\n",
    "    # Tentukan sumber data yang akan dimuat\n",
    "    sources_to_load = ['masked']\n",
    "    if use_both and 'unmasked' in dataset_sources:\n",
    "        sources_to_load.append('unmasked')\n",
    "\n",
    "    log(f\"Loading from sources: {sources_to_load}\")\n",
    "\n",
    "    person_images = {}\n",
    "\n",
    "    # Loop untuk setiap sumber data (masked/unmasked)\n",
    "    for source_name in sources_to_load:\n",
    "        if source_name not in dataset_sources:\n",
    "            continue\n",
    "\n",
    "        source_path = Path(dataset_sources[source_name])\n",
    "\n",
    "        if not source_path.exists():\n",
    "            log(f\"⚠ Warning: {source_name} path does not exist: {source_path}\")\n",
    "            continue\n",
    "\n",
    "        log(f\"\\nScanning {source_name}: {source_path}\")\n",
    "\n",
    "        # Dapatkan semua folder orang dalam sumber data\n",
    "        person_folders = sorted([d for d in source_path.iterdir() if d.is_dir()])\n",
    "        log(f\"  Found {len(person_folders)} person folders\")\n",
    "\n",
    "        for person_dir in person_folders:\n",
    "            person_name = person_dir.name\n",
    "\n",
    "            # Ambil semua file gambar (jpg, png, jpeg)\n",
    "            image_files = list(person_dir.glob('*.jpg')) + \\\n",
    "                          list(person_dir.glob('*.png')) + \\\n",
    "                          list(person_dir.glob('*.jpeg'))\n",
    "\n",
    "            # Batasi jumlah gambar sesuai parameter limit\n",
    "            image_files = image_files[:limit]\n",
    "\n",
    "            if person_name not in person_images:\n",
    "                person_images[person_name] = []\n",
    "\n",
    "            person_images[person_name].extend(image_files)\n",
    "\n",
    "    # Buat mapping dari nama orang ke ID numerik\n",
    "    label_to_id = {name: idx for idx, name in enumerate(sorted(person_images.keys()))}\n",
    "\n",
    "    # Flatten data menjadi list path gambar dan list label\n",
    "    all_image_paths = []\n",
    "    all_labels = []\n",
    "\n",
    "    for person_name, img_paths in person_images.items():\n",
    "        label_id = label_to_id[person_name]\n",
    "        for img_path in img_paths:\n",
    "            all_image_paths.append(img_path)\n",
    "            all_labels.append(label_id)\n",
    "\n",
    "    return all_image_paths, all_labels, label_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqWfRLSIG1W3"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## **[3] Face Detection, Alignment, and Upper Face Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q409Aw5Zn74-"
   },
   "outputs": [],
   "source": [
    "def get_eye_center(landmarks, image_shape, eye_indices):\n",
    "    \"\"\"\n",
    "    Menghitung titik tengah mata dari landmark yang terdeteksi\n",
    "\n",
    "    Parameter:\n",
    "        landmarks: List landmark wajah dari MediaPipe\n",
    "        image_shape: Ukuran gambar (height, width)\n",
    "        eye_indices: Indeks landmark untuk mata tertentu\n",
    "\n",
    "    Return:\n",
    "        center: Koordinat [x, y] titik tengah mata\n",
    "    \"\"\"\n",
    "    h, w = image_shape[:2]\n",
    "    pts = []\n",
    "\n",
    "    # Konversi landmark yang dinormalisasi ke koordinat pixel\n",
    "    for idx in eye_indices:\n",
    "        x = int(landmarks[idx].x * w)\n",
    "        y = int(landmarks[idx].y * h)\n",
    "        pts.append([x, y])\n",
    "\n",
    "    pts = np.array(pts)\n",
    "    center = np.mean(pts, axis=0)  # Hitung rata-rata posisi\n",
    "\n",
    "    return np.array([int(center[0]), int(center[1])])\n",
    "\n",
    "def crop_eye_roi(image, landmarks):\n",
    "    \"\"\"\n",
    "    Memotong region mata dari gambar wajah\n",
    "\n",
    "    Parameter:\n",
    "        image: Gambar wajah input\n",
    "        landmarks: List landmark wajah dari MediaPipe\n",
    "\n",
    "    Return:\n",
    "        eye_crop: Gambar region mata yang telah dipotong\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    # Konversi semua landmark ke koordinat pixel\n",
    "    pts = np.array([[int(l.x * w), int(l.y * h)] for l in landmarks])\n",
    "\n",
    "    # Ambil titik landmark untuk mata kiri dan kanan\n",
    "    left_eye_pts = pts[LEFT_EYE_INDICES]\n",
    "    right_eye_pts = pts[RIGHT_EYE_INDICES]\n",
    "\n",
    "    # Gabungkan kedua mata\n",
    "    eyes = np.vstack([left_eye_pts, right_eye_pts])\n",
    "\n",
    "    # Dapatkan bounding box di sekitar region mata\n",
    "    x_min, y_min = eyes.min(axis=0)\n",
    "    x_max, y_max = eyes.max(axis=0)\n",
    "\n",
    "    # Tambahkan margin di sekitar mata untuk konteks lebih baik\n",
    "    margin_x = int((x_max - x_min) * 0.1)   # 10% margin horizontal\n",
    "    margin_y = int((y_max - y_min) * 1.75)  # 175% margin vertikal (untuk alis)\n",
    "\n",
    "    # Pastikan tidak keluar dari batas gambar\n",
    "    x_min = max(0, x_min - margin_x)\n",
    "    y_min = max(0, y_min - margin_y)\n",
    "    x_max = min(w, x_max + margin_x)\n",
    "    y_max = min(h, y_max + margin_y)\n",
    "\n",
    "    # Potong region mata dari gambar\n",
    "    eye_crop = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    if eye_crop.size == 0:\n",
    "        return None\n",
    "\n",
    "    return eye_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5HQ5F6BBWuh"
   },
   "outputs": [],
   "source": [
    "def face_detection_pipeline(image_path):\n",
    "    \"\"\"\n",
    "    Pipeline untuk mendeteksi wajah, alignment, dan crop region mata\n",
    "\n",
    "    Parameter:\n",
    "        image_path: Path ke file gambar\n",
    "\n",
    "    Return:\n",
    "        eye_roi_image: Gambar region mata yang telah di-align dan di-crop\n",
    "    \"\"\"\n",
    "    # Load gambar dari file\n",
    "    image = cv2.imread(str(image_path))\n",
    "    if image is None:\n",
    "        return None\n",
    "\n",
    "    # Konversi ke RGB untuk MediaPipe\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Deteksi wajah menggunakan MediaPipe Face Mesh\n",
    "    results = face_mesh.process(image_rgb)\n",
    "\n",
    "    # Cek apakah wajah terdeteksi\n",
    "    if not results.multi_face_landmarks:\n",
    "        return None\n",
    "\n",
    "    landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "    # Dapatkan posisi titik tengah mata kiri dan kanan\n",
    "    left_eye = get_eye_center(landmarks, image.shape, LEFT_EYE_INDICES)\n",
    "    right_eye = get_eye_center(landmarks, image.shape, RIGHT_EYE_INDICES)\n",
    "\n",
    "    # Hitung sudut rotasi dari posisi mata untuk alignment\n",
    "    dy = right_eye[1] - left_eye[1]\n",
    "    dx = right_eye[0] - left_eye[0]\n",
    "    angle = np.degrees(np.arctan2(dy, dx))\n",
    "\n",
    "    # Lakukan alignment hanya jika sudut rotasi signifikan (> 2 derajat)\n",
    "    if abs(angle) > 2.0:\n",
    "        h, w = image.shape[:2]\n",
    "        # Titik tengah antara kedua mata sebagai pusat rotasi\n",
    "        eye_center = (\n",
    "            float((left_eye[0] + right_eye[0]) / 2),\n",
    "            float((left_eye[1] + right_eye[1]) / 2)\n",
    "        )\n",
    "\n",
    "        # Buat matriks transformasi affine untuk rotasi\n",
    "        M = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "\n",
    "        # Terapkan rotasi pada gambar\n",
    "        aligned = cv2.warpAffine(\n",
    "            image, M,\n",
    "            (w, h),\n",
    "            flags=cv2.INTER_CUBIC\n",
    "        )\n",
    "\n",
    "        # Transform landmark menggunakan matriks affine yang sama\n",
    "        aligned_landmarks = []\n",
    "        for lm in landmarks:\n",
    "            x = lm.x * w\n",
    "            y = lm.y * h\n",
    "            # Terapkan transformasi affine\n",
    "            new_x = M[0, 0] * x + M[0, 1] * y + M[0, 2]\n",
    "            new_y = M[1, 0] * x + M[1, 1] * y + M[1, 2]\n",
    "\n",
    "            # Buat objek landmark baru dengan koordinat yang sudah di-transform\n",
    "            aligned_lm = type('Landmark', (), {\n",
    "                'x': new_x / w,  # Normalisasi kembali\n",
    "                'y': new_y / h\n",
    "            })()\n",
    "            aligned_landmarks.append(aligned_lm)\n",
    "\n",
    "        landmarks = aligned_landmarks\n",
    "    else:\n",
    "        # Tidak perlu alignment jika sudut kecil\n",
    "        aligned = image\n",
    "\n",
    "    # Crop region mata dari gambar yang sudah di-align\n",
    "    eye_roi_image = crop_eye_roi(aligned, landmarks)\n",
    "\n",
    "    return eye_roi_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_60___J0HTpT"
   },
   "source": [
    "## **[4] Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWZdDorgbcNN"
   },
   "outputs": [],
   "source": [
    "def preprocessing_pipeline(eye_roi_image, target_size=(160, 160)):\n",
    "    \"\"\"\n",
    "    Pipeline preprocessing untuk meningkatkan kualitas gambar\n",
    "\n",
    "    Parameter:\n",
    "        eye_roi_image: Gambar region mata\n",
    "        target_size: Ukuran target untuk resize (default: 160x160)\n",
    "\n",
    "    Return:\n",
    "        denoised_image: Gambar yang telah diproses\n",
    "    \"\"\"\n",
    "    # 1. Resize gambar ke ukuran target\n",
    "    resized_image = cv2.resize(eye_roi_image, target_size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # 2. Konversi ke grayscale\n",
    "    gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 3. CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    #    Meningkatkan kontras lokal tanpa over-amplification\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(gray_image)\n",
    "\n",
    "    # 4. Gaussian blur untuk mengurangi noise\n",
    "    denoised_image = cv2.GaussianBlur(enhanced_image, (3, 3), 0)\n",
    "\n",
    "    return denoised_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5eY-WHmFcF9S"
   },
   "outputs": [],
   "source": [
    "def augmenting_pipeline(image, n_aug=8):\n",
    "    \"\"\"\n",
    "    Pipeline augmentasi data untuk meningkatkan variasi dataset\n",
    "\n",
    "    Parameter:\n",
    "        image: Gambar input\n",
    "        n_aug: Jumlah variasi augmentasi yang akan dibuat (default: 8)\n",
    "\n",
    "    Return:\n",
    "        augmented: List berisi gambar asli + semua hasil augmentasi\n",
    "    \"\"\"\n",
    "    augmented = [image]  # Simpan gambar asli\n",
    "    h, w = image.shape\n",
    "\n",
    "    for _ in range(n_aug):\n",
    "        aug = image.copy()\n",
    "\n",
    "        # 1. Variasi brightness (kecerahan) yang lebih agresif\n",
    "        brightness = np.random.uniform(-40, 40)\n",
    "        aug = np.clip(aug.astype(np.float32) + brightness, 0, 255).astype(np.uint8)\n",
    "\n",
    "        # 2. Penyesuaian contrast\n",
    "        alpha = np.random.uniform(0.8, 1.2)\n",
    "        aug = np.clip(alpha * aug, 0, 255).astype(np.uint8)\n",
    "\n",
    "        # 3. Tambahkan noise secara acak (30% kemungkinan)\n",
    "        if np.random.rand() > 0.7:\n",
    "            noise = np.random.normal(0, 5, aug.shape)\n",
    "            aug = np.clip(aug + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "        # 4. Gaussian blur (40% kemungkinan)\n",
    "        if np.random.rand() > 0.6:\n",
    "            aug = cv2.GaussianBlur(aug, (3, 3), 0)\n",
    "\n",
    "        # 5. Horizontal flip - valid untuk mata (50% kemungkinan)\n",
    "        if np.random.rand() > 0.5:\n",
    "            aug = cv2.flip(aug, 1)\n",
    "\n",
    "        # 6. Rotasi kecil (-5 hingga 5 derajat)\n",
    "        angle = np.random.uniform(-5, 5)\n",
    "        M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n",
    "        aug = cv2.warpAffine(aug, M, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "\n",
    "        # 7. Scale dan translasi kecil\n",
    "        scale = np.random.uniform(0.92, 1.08)\n",
    "        M2 = np.array([[scale, 0, np.random.uniform(-5, 5)],\n",
    "                       [0, scale, np.random.uniform(-5, 5)]], dtype=np.float32)\n",
    "        aug = cv2.warpAffine(aug, M2, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "\n",
    "        augmented.append(aug)\n",
    "\n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRTopsoHpV1P"
   },
   "source": [
    "## **[5] Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArjWUNK3pZK6"
   },
   "outputs": [],
   "source": [
    "def feature_extraction_pipeline(equalized_image, grid_size=(4, 4)):\n",
    "    \"\"\"\n",
    "    Ekstraksi fitur menggunakan multi-scale LBP (Local Binary Pattern)\n",
    "\n",
    "    Parameter:\n",
    "        equalized_image: Gambar yang telah di-preprocessing\n",
    "        grid_size: Ukuran grid untuk membagi gambar (default: 4x4)\n",
    "\n",
    "    Return:\n",
    "        features: Array 1D berisi semua fitur LBP yang telah di-concatenate\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "\n",
    "    # Konfigurasi multi-scale LBP dengan berbagai radius dan points\n",
    "    lbp_configs = [\n",
    "        (1, 8),   # Fine details - detail halus\n",
    "        (2, 16),  # Medium details - detail menengah\n",
    "        (3, 24),  # Coarse details - detail kasar\n",
    "    ]\n",
    "\n",
    "    # Ekstrak fitur untuk setiap skala\n",
    "    for radius, n_points in lbp_configs:\n",
    "        n_bins = n_points + 2  # Jumlah bin untuk histogram\n",
    "\n",
    "        # Hitung LBP uniform pattern\n",
    "        lbp = local_binary_pattern(equalized_image, n_points, radius, method='uniform')\n",
    "\n",
    "        h, w = equalized_image.shape\n",
    "        grid_y, grid_x = grid_size\n",
    "        cell_h, cell_w = h // grid_y, w // grid_x\n",
    "\n",
    "        cell_features = []\n",
    "\n",
    "        # Bagi gambar menjadi grid dan ekstrak histogram dari setiap cell\n",
    "        for gy in range(grid_y):\n",
    "            for gx in range(grid_x):\n",
    "                # Tentukan batas cell\n",
    "                y0, y1 = gy * cell_h, (gy + 1) * cell_h if gy < grid_y - 1 else h\n",
    "                x0, x1 = gx * cell_w, (gx + 1) * cell_w if gx < grid_x - 1 else w\n",
    "\n",
    "                # Ambil LBP dari cell\n",
    "                cell_lbp = lbp[y0:y1, x0:x1]\n",
    "\n",
    "                # Hitung histogram dengan normalisasi densitas\n",
    "                hist, _ = np.histogram(cell_lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "\n",
    "                # L2 normalization untuk invariance terhadap pencahayaan\n",
    "                norm = np.linalg.norm(hist)\n",
    "                if norm > 1e-7:\n",
    "                    hist = hist / norm\n",
    "\n",
    "                cell_features.append(hist)\n",
    "\n",
    "        # Gabungkan semua histogram dari grid untuk skala ini\n",
    "        features_list.append(np.concatenate(cell_features))\n",
    "\n",
    "    # Gabungkan fitur dari semua skala menjadi satu vektor fitur\n",
    "    return np.concatenate(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TN7Y04K3pynH"
   },
   "source": [
    "## **[6] Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kBFRdsmpynJ"
   },
   "outputs": [],
   "source": [
    "def knn_fit(X_train, y_train, k=5, metric=\"cosine\", weights=\"distance\"):\n",
    "    \"\"\"\n",
    "    Melatih model KNN classifier\n",
    "\n",
    "    Parameter:\n",
    "        X_train: Fitur training\n",
    "        y_train: Label training\n",
    "        k: Jumlah tetangga terdekat (default: 5)\n",
    "        metric: Metrik jarak (default: cosine)\n",
    "        weights: Bobot tetangga (default: distance)\n",
    "\n",
    "    Return:\n",
    "        knn: Model KNN yang telah dilatih\n",
    "    \"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights=weights)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    train_score = knn.score(X_train, y_train)\n",
    "    print(f\"KNN Training Score: {train_score:.4f}\")\n",
    "    return knn\n",
    "\n",
    "def evaluate_knn(knn, X_test, y_test, label_to_id):\n",
    "    \"\"\"\n",
    "    Evaluasi model KNN secara komprehensif\n",
    "\n",
    "    Parameter:\n",
    "        knn: Model KNN yang telah dilatih\n",
    "        X_test: Fitur testing\n",
    "        y_test: Label testing\n",
    "        label_to_id: Dictionary mapping nama ke ID\n",
    "\n",
    "    Return:\n",
    "        accuracy: Akurasi model pada test set\n",
    "        y_pred: Prediksi label untuk test set\n",
    "    \"\"\"\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # Hitung metrik evaluasi\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EVALUASI MODEL KNN\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Akurasi Test: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Classification report untuk kelas-kelas teratas\n",
    "    id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "    target_names = [id_to_label[i] for i in sorted(set(y_test))]\n",
    "\n",
    "    print(\"\\nClassification Report (sample):\")\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names,\n",
    "                                labels=sorted(set(y_test))[:10], zero_division=0))\n",
    "\n",
    "    return accuracy, y_pred\n",
    "\n",
    "def cross_validate_knn(X, y, k=5, cv=5):\n",
    "    \"\"\"\n",
    "    Melakukan cross-validation pada model KNN\n",
    "\n",
    "    Parameter:\n",
    "        X: Fitur dataset\n",
    "        y: Label dataset\n",
    "        k: Jumlah tetangga (default: 5)\n",
    "        cv: Jumlah fold untuk cross-validation (default: 5)\n",
    "\n",
    "    Return:\n",
    "        scores: Array berisi skor akurasi untuk setiap fold\n",
    "    \"\"\"\n",
    "    log(f\"Performing {cv}-fold cross-validation...\")\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='cosine', weights='distance')\n",
    "    scores = cross_val_score(knn, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "    print(f\"\\nCross-Validation Scores: {scores}\")\n",
    "    print(f\"Mean CV Accuracy: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "\n",
    "    return scores\n",
    "\n",
    "print(\"✓ Classification functions defined!\")\n",
    "\n",
    "\n",
    "def find_optimal_k(X_train_pca, y_train, scaler, pca, label_to_id, test_images_dir, k_range=range(1, 21)):\n",
    "    \"\"\"\n",
    "    Mencari nilai k optimal dengan mengevaluasi performa pada dataset test eksternal\n",
    "\n",
    "    Parameter:\n",
    "        X_train_pca: Fitur training yang sudah direduksi dimensi (PCA)\n",
    "        y_train: Label training\n",
    "        scaler: Scaler yang sudah difit pada training data\n",
    "        pca: PCA yang sudah difit pada training data\n",
    "        label_to_id: Dictionary mapping nama ke ID\n",
    "        test_images_dir: Direktori berisi gambar test\n",
    "        k_range: Range nilai k yang akan diuji\n",
    "\n",
    "    Return:\n",
    "        optimal_k: Nilai k dengan akurasi tertinggi\n",
    "        results: Dictionary berisi akurasi untuk setiap k\n",
    "    \"\"\"\n",
    "    print(f\"Mencari optimal k dalam range {k_range.start}-{k_range.stop-1}...\")\n",
    "    \n",
    "    # 1. Load dan proses semua gambar test terlebih dahulu (supaya tidak berulang)\n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "    \n",
    "    test_path = Path(test_images_dir)\n",
    "    if not test_path.exists():\n",
    "        print(f\"Error: Directory {test_images_dir} not found!\")\n",
    "        return CONFIG['NEIGHBORS'], {}\n",
    "        \n",
    "    print(\"Memproses test images...\")\n",
    "    for img_file in test_path.glob('*'):\n",
    "        if img_file.suffix.lower() not in ['.jpg', '.jpeg', '.png']:\n",
    "            continue\n",
    "            \n",
    "        # Asumsi format nama file: \"nama_apapunsajatextlain.jpg\"\n",
    "        # Kita ambil kata pertama sebagai nama orang\n",
    "        # Contoh: \"esa_test.jpg\" -> \"esa\"\n",
    "        person_name = img_file.stem.split('_')[0].lower()\n",
    "        \n",
    "        # Cari label ID yang cocok (case-insensitive)\n",
    "        # Kita harus mencocokkan nama di file dengan key di label_to_id\n",
    "        matched_label = None\n",
    "        for label_name, label_id in label_to_id.items():\n",
    "            if person_name == label_name.lower() or person_name in label_name.lower():\n",
    "                matched_label = label_id\n",
    "                break\n",
    "        \n",
    "        if matched_label is None:\n",
    "            print(f\"  ⚠ Skipping {img_file.name}: Label '{person_name}' tidak ditemukan di dataset.\")\n",
    "            continue\n",
    "            \n",
    "        # Pipeline pemrosesan gambar (sama seperti inference)\n",
    "        try:\n",
    "            # a. Deteksi wajah\n",
    "            roi = face_detection_pipeline(img_file)\n",
    "            if roi is None:\n",
    "                print(f\"  ⚠ Skipping {img_file.name}: Wajah tidak terdeteksi.\")\n",
    "                continue\n",
    "                \n",
    "            # b. Preprocessing\n",
    "            processed = preprocessing_pipeline(roi, target_size=CONFIG['EYE_ROI_TARGET_SIZE'])\n",
    "            \n",
    "            # c. Ekstraksi Fitur\n",
    "            feats = feature_extraction_pipeline(processed)\n",
    "            \n",
    "            # d. Transformasi (Scale + PCA)\n",
    "            # Perlu reshape ke (1, -1) dulu karena single sample, lalu di-flatten kembali\n",
    "            feats = feats.reshape(1, -1)\n",
    "            feats_scaled = scaler.transform(feats)\n",
    "            feats_pca = pca.transform(feats_scaled)\n",
    "            \n",
    "            test_data.append(feats_pca[0]) # Ambil [0] supaya jadi 1D array\n",
    "            test_labels.append(matched_label)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠ Error processing {img_file.name}: {str(e)}\")\n",
    "\n",
    "    if not test_data:\n",
    "        print(\"Tidak ada data test yang valid. Menggunakan default k.\")\n",
    "        return CONFIG['NEIGHBORS'], {}\n",
    "\n",
    "    test_data = np.array(test_data)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    print(f\"Total {len(test_data)} gambar test valid siap digunakan untuk validasi.\")\n",
    "\n",
    "    # 2. Iterasi nilai k\n",
    "    accuracies = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        # Train KNN sementara\n",
    "        knn_temp = KNeighborsClassifier(n_neighbors=k, metric='cosine', weights='distance')\n",
    "        knn_temp.fit(X_train_pca, y_train)\n",
    "        \n",
    "        # Evaluasi\n",
    "        pred_labels = knn_temp.predict(test_data)\n",
    "        acc = accuracy_score(test_labels, pred_labels)\n",
    "        accuracies.append(acc)\n",
    "        print(f\"  k={k}: Accuracy={acc:.2f}\")\n",
    "\n",
    "    # 3. Visualisasi Hasil\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_range, accuracies, marker='o', linestyle='-', color='#2980b9', linewidth=2)\n",
    "    plt.title('Optimal k Selection based on Test Images', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Number of Neighbors (k)', fontsize=12)\n",
    "    plt.ylabel('Accuracy on Test Set', fontsize=12)\n",
    "    plt.xticks(k_range)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Highlight best k\n",
    "    best_idx = np.argmax(accuracies)\n",
    "    best_k = k_range[best_idx]\n",
    "    best_acc = accuracies[best_idx]\n",
    "    \n",
    "    plt.plot(best_k, best_acc, 'or', markersize=12, label=f'Best k={best_k} (Acc: {best_acc:.2%})')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\\\n✅ Optimal k found: {best_k} with accuracy {best_acc:.2%}\")\n",
    "    return dict(zip(k_range, accuracies))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxNw-gCWuIsV"
   },
   "source": [
    "## **[7] Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3FEtUosuMv0"
   },
   "outputs": [],
   "source": [
    "def plot_class_distribution(labels, label_to_id, top_n=20):\n",
    "    \"\"\"\n",
    "    Visualisasi distribusi jumlah sampel per kelas\n",
    "\n",
    "    Parameter:\n",
    "        labels: List label dari dataset\n",
    "        label_to_id: Dictionary mapping nama ke ID\n",
    "        top_n: Jumlah kelas teratas yang ditampilkan (default: 20)\n",
    "    \"\"\"\n",
    "    id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "    label_names = [id_to_label[l] for l in labels]\n",
    "\n",
    "    from collections import Counter\n",
    "    counts = Counter(label_names)\n",
    "\n",
    "    # Ambil top N kelas dengan sampel terbanyak\n",
    "    top_classes = counts.most_common(top_n)\n",
    "    names, values = zip(*top_classes)\n",
    "\n",
    "    # Buat visualisasi bar chart\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    bars = plt.bar(range(len(names)), values, color='#3498db', edgecolor='#2c3e50',\n",
    "                   alpha=0.85, linewidth=1.5)\n",
    "\n",
    "    plt.xlabel('Nama Orang', fontsize=13, fontweight='bold')\n",
    "    plt.ylabel('Jumlah Gambar', fontsize=13, fontweight='bold')\n",
    "    plt.title(f'Top {top_n} Kelas Berdasarkan Jumlah Sampel (Total: {len(label_to_id)} kelas)',\n",
    "              fontsize=15, fontweight='bold', pad=20)\n",
    "    plt.xticks(range(len(names)), names, rotation=45, ha='right', fontsize=10)\n",
    "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Tambahkan label nilai di atas setiap bar\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{int(height)}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Tampilkan statistik\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Total sampel: {len(labels)}\")\n",
    "    print(f\"Total kelas: {len(label_to_id)}\")\n",
    "    print(f\"Rata-rata sampel per kelas: {len(labels)/len(label_to_id):.2f}\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "\n",
    "def visualize_feature_samples(images, labels, label_to_id, n_samples=10):\n",
    "    \"\"\"\n",
    "    Visualisasi sampel acak dari dataset\n",
    "\n",
    "    Parameter:\n",
    "        images: List gambar\n",
    "        labels: List label\n",
    "        label_to_id: Dictionary mapping nama ke ID\n",
    "        n_samples: Jumlah sampel yang ditampilkan (default: 10)\n",
    "    \"\"\"\n",
    "    id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "\n",
    "    # Pilih indeks secara acak\n",
    "    indices = np.random.choice(len(images), min(n_samples, len(images)), replace=False)\n",
    "\n",
    "    rows = 2\n",
    "    cols = 5\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(18, 7))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, ax in enumerate(axes):\n",
    "        if idx < len(indices):\n",
    "            img_idx = indices[idx]\n",
    "            img = images[img_idx]\n",
    "            label_id = labels[img_idx]\n",
    "            person_name = id_to_label[label_id]\n",
    "\n",
    "            # Tampilkan gambar\n",
    "            if len(img.shape) == 3:\n",
    "                ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            else:\n",
    "                ax.imshow(img, cmap='gray')\n",
    "\n",
    "            # Potong nama jika terlalu panjang\n",
    "            display_name = person_name[:20] + '...' if len(person_name) > 20 else person_name\n",
    "            ax.set_title(f\"{display_name}\", fontsize=11, fontweight='bold', pad=8)\n",
    "\n",
    "            # Tambahkan border\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor('#2c3e50')\n",
    "                spine.set_linewidth(2)\n",
    "\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle('Contoh Gambar Acak dari Dataset', fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, label_to_id, top_n=15):\n",
    "    \"\"\"\n",
    "    Visualisasi confusion matrix untuk kelas-kelas teratas\n",
    "\n",
    "    Parameter:\n",
    "        y_true: Label sebenarnya\n",
    "        y_pred: Label prediksi\n",
    "        label_to_id: Dictionary mapping nama ke ID\n",
    "        top_n: Jumlah kelas yang ditampilkan (default: 15)\n",
    "    \"\"\"\n",
    "    id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "\n",
    "    # Ambil top N kelas paling umum\n",
    "    from collections import Counter\n",
    "    class_counts = Counter(y_true)\n",
    "    top_classes = [cls for cls, _ in class_counts.most_common(top_n)]\n",
    "\n",
    "    # Filter prediksi untuk top classes saja\n",
    "    mask = np.isin(y_true, top_classes)\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "\n",
    "    # Buat confusion matrix\n",
    "    cm = confusion_matrix(y_true_filtered, y_pred_filtered, labels=top_classes)\n",
    "\n",
    "    # Normalisasi\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Visualisasi\n",
    "    plt.figure(figsize=(14, 11))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=[id_to_label[i][:15] for i in top_classes],\n",
    "                yticklabels=[id_to_label[i][:15] for i in top_classes],\n",
    "                cbar_kws={'label': 'Akurasi'}, linewidths=0.5, linecolor='gray')\n",
    "\n",
    "    plt.title(f'Confusion Matrix (Normalized) - Top {top_n} Kelas',\n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.ylabel('Label Sebenarnya', fontsize=13, fontweight='bold')\n",
    "    plt.xlabel('Label Prediksi', fontsize=13, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_dimensionality(features_original, features_reduced, variance_explained=None):\n",
    "    \"\"\"\n",
    "    Visualisasi perbandingan dimensi fitur sebelum dan sesudah reduksi\n",
    "\n",
    "    Parameter:\n",
    "        features_original: Fitur asli sebelum reduksi\n",
    "        features_reduced: Fitur setelah reduksi (PCA)\n",
    "        variance_explained: Proporsi variance yang dipertahankan\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Grafik fitur asli\n",
    "    axes[0].bar(['Fitur Asli'], [features_original.shape[1]],\n",
    "                color='#e74c3c', edgecolor='#c0392b', alpha=0.8, width=0.5, linewidth=2)\n",
    "    axes[0].set_ylabel('Jumlah Fitur', fontsize=13, fontweight='bold')\n",
    "    axes[0].set_title('Dimensi Fitur Asli', fontsize=14, fontweight='bold', pad=15)\n",
    "    axes[0].text(0, features_original.shape[1] + 20, f'{features_original.shape[1]} dims',\n",
    "                ha='center', va='bottom', fontsize=16, fontweight='bold')\n",
    "    axes[0].set_ylim(0, features_original.shape[1] * 1.15)\n",
    "    axes[0].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Grafik fitur hasil reduksi\n",
    "    axes[1].bar(['Fitur PCA'], [features_reduced.shape[1]],\n",
    "                color='#27ae60', edgecolor='#229954', alpha=0.8, width=0.5, linewidth=2)\n",
    "    axes[1].set_ylabel('Jumlah Fitur', fontsize=13, fontweight='bold')\n",
    "    axes[1].set_title('Dimensi Fitur Setelah PCA', fontsize=14, fontweight='bold', pad=15)\n",
    "    axes[1].text(0, features_reduced.shape[1] + 20, f'{features_reduced.shape[1]} dims',\n",
    "                ha='center', va='bottom', fontsize=16, fontweight='bold')\n",
    "    axes[1].set_ylim(0, features_original.shape[1] * 1.15)\n",
    "    axes[1].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Tambahkan info variance jika tersedia\n",
    "    if variance_explained is not None:\n",
    "        axes[1].text(0, features_reduced.shape[1] * 0.6,\n",
    "                    f'Variance: {variance_explained:.1%}',\n",
    "                    ha='center', fontsize=11, fontweight='bold',\n",
    "                    bbox=dict(boxstyle='round', facecolor='#f39c12', alpha=0.7,\n",
    "                             edgecolor='#d68910', linewidth=2))\n",
    "\n",
    "    # Tambahkan info reduksi\n",
    "    reduction = (1 - features_reduced.shape[1]/features_original.shape[1]) * 100\n",
    "    fig.text(0.5, 0.02, f'Reduksi Dimensi: {reduction:.1f}%',\n",
    "             ha='center', fontsize=13, fontweight='bold',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8,\n",
    "                      edgecolor='black', linewidth=1.5))\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "    plt.show()\n",
    "\n",
    "def calculate_psnr_mse_val(img1, img2):\n",
    "    \"\"\"\n",
    "    Menghitung PSNR (Peak Signal-to-Noise Ratio) dan MSE antara dua gambar\n",
    "\n",
    "    Parameter:\n",
    "        img1: Gambar pertama\n",
    "        img2: Gambar kedua\n",
    "\n",
    "    Return:\n",
    "        psnr: Nilai PSNR dalam dB\n",
    "        mse: Nilai Mean Squared Error\n",
    "    \"\"\"\n",
    "    # Konversi ke grayscale jika perlu\n",
    "    if len(img1.shape) == 3:\n",
    "        img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    if len(img2.shape) == 3:\n",
    "        img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Hitung MSE\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "\n",
    "    # Jika MSE = 0, gambar identik\n",
    "    if mse == 0:\n",
    "        return float('inf'), 0\n",
    "\n",
    "    # Hitung PSNR\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "\n",
    "    return psnr, mse\n",
    "\n",
    "print(\"✓ Visualization functions added!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuoDWKHZ6_SO"
   },
   "source": [
    "## **[8] Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlvZCm3c604k"
   },
   "outputs": [],
   "source": [
    "def load_trained_model(model_path):\n",
    "    \"\"\"\n",
    "    Memuat model yang telah dilatih dari file\n",
    "\n",
    "    Parameter:\n",
    "        model_path: Path ke file model (.pkl)\n",
    "\n",
    "    Return:\n",
    "        knn_model: Model KNN yang telah dilatih\n",
    "        pca: Model PCA untuk reduksi dimensi\n",
    "        scaler: StandardScaler untuk normalisasi\n",
    "        label_to_id: Dictionary mapping nama ke ID\n",
    "    \"\"\"\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "\n",
    "    log(f\"✓ Model loaded successfully!\")\n",
    "    log(f\"  Dimensi fitur asli: {model_data['config']['feature_dim_original']}\")\n",
    "    log(f\"  Dimensi fitur PCA: {model_data['config']['feature_dim_pca']}\")\n",
    "    log(f\"  Jumlah kelas: {len(model_data['label_to_id'])}\")\n",
    "    log(f\"  Akurasi test: {model_data['config']['test_accuracy']:.4f}\")\n",
    "\n",
    "    return model_data['knn_model'], model_data['pca'], model_data['scaler'], model_data['label_to_id']\n",
    "\n",
    "def inference_pipeline(image_path, model, pca, scaler, label_to_id, target_size=(96, 32)):\n",
    "    \"\"\"\n",
    "    Pipeline inferensi lengkap untuk pengenalan wajah dengan visualisasi detail\n",
    "\n",
    "    Parameter:\n",
    "        image_path: Path ke gambar yang akan diprediksi\n",
    "        model: Model KNN yang telah dilatih\n",
    "        pca: Model PCA untuk reduksi dimensi\n",
    "        scaler: StandardScaler untuk normalisasi\n",
    "        label_to_id: Dictionary mapping nama ke ID\n",
    "        target_size: Ukuran target untuk preprocessing\n",
    "    \"\"\"\n",
    "    # ========== TAHAP 1: Load Gambar Asli ==========\n",
    "    original = cv2.imread(str(image_path))\n",
    "    if original is None:\n",
    "        print(f\"Gagal memuat gambar: {image_path}\")\n",
    "        return\n",
    "    original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # ========== TAHAP 2: Deteksi Wajah & Ekstraksi ROI ==========\n",
    "    roi = face_detection_pipeline(image_path)\n",
    "    if roi is None:\n",
    "        print(f'Tidak ada wajah terdeteksi dalam: {image_path}')\n",
    "        return\n",
    "\n",
    "    roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # ========== TAHAP 3: Preprocessing ==========\n",
    "    resized = cv2.resize(roi, target_size, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "    processed = preprocessing_pipeline(roi, target_size)\n",
    "\n",
    "    # Hitung kualitas gambar (PSNR & MSE)\n",
    "    psnr, mse = calculate_psnr_mse_val(gray, processed)\n",
    "\n",
    "    # ========== TAHAP 4: Ekstraksi Fitur LBP ==========\n",
    "    radius = 3\n",
    "    n_points = 24\n",
    "    lbp_map = local_binary_pattern(processed, n_points, radius, method='uniform')\n",
    "\n",
    "    # ========== TAHAP 5: Ekstraksi Fitur & Klasifikasi ==========\n",
    "    feats = feature_extraction_pipeline(processed)\n",
    "    feats = feats.reshape(1, -1)\n",
    "    feats_scaled = scaler.transform(feats)\n",
    "    feats_pca = pca.transform(feats_scaled)\n",
    "\n",
    "    # Prediksi identitas\n",
    "    pred_id = model.predict(feats_pca)[0]\n",
    "    proba = model.predict_proba(feats_pca)\n",
    "    confidence = np.max(proba)\n",
    "\n",
    "    # Ambil top 3 prediksi\n",
    "    top_3_idx = np.argsort(proba[0])[-3:][::-1]\n",
    "    top_3_proba = proba[0][top_3_idx]\n",
    "\n",
    "    id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "    pred_name = id_to_label[pred_id]\n",
    "    top_3_names = [id_to_label[idx] for idx in top_3_idx]\n",
    "\n",
    "    # ========== VISUALISASI PIPELINE ==========\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    gs = fig.add_gridspec(2, 3, hspace=0.35, wspace=0.3,\n",
    "                          left=0.05, right=0.95, top=0.93, bottom=0.05)\n",
    "\n",
    "    # 1. Gambar Asli\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.imshow(original_rgb)\n",
    "    ax1.set_title('① Gambar Asli', fontweight='bold', fontsize=13, pad=10)\n",
    "    ax1.axis('off')\n",
    "\n",
    "    # 2. Region Mata (ROI)\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.imshow(roi_rgb)\n",
    "    ax2.set_title('② Region Mata (ROI)', fontweight='bold', fontsize=13, pad=10)\n",
    "    ax2.axis('off')\n",
    "\n",
    "    # 3. Hasil Preprocessing\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.imshow(processed, cmap='gray')\n",
    "    ax3.set_title(f'③ Preprocessing\\nPSNR: {psnr:.2f} dB | MSE: {mse:.2f}',\n",
    "                  fontweight='bold', fontsize=13, pad=10)\n",
    "    ax3.axis('off')\n",
    "\n",
    "    # 4. LBP Feature Map\n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    lbp_display = ax4.imshow(lbp_map, cmap='viridis')\n",
    "    ax4.set_title('④ Peta Fitur LBP', fontweight='bold', fontsize=13, pad=10)\n",
    "    ax4.axis('off')\n",
    "    plt.colorbar(lbp_display, ax=ax4, fraction=0.046, pad=0.04)\n",
    "\n",
    "    # 5. Perbandingan Histogram\n",
    "    ax5 = fig.add_subplot(gs[1, 1])\n",
    "    ax5.hist(gray.ravel(), bins=64, range=(0, 256), alpha=0.7,\n",
    "            label='Sebelum', color='#e74c3c', edgecolor='black', linewidth=0.5)\n",
    "    ax5.hist(processed.ravel(), bins=64, range=(0, 256), alpha=0.7,\n",
    "            label='Sesudah', color='#3498db', edgecolor='black', linewidth=0.5)\n",
    "    ax5.set_xlabel('Intensitas Pixel', fontweight='bold', fontsize=11)\n",
    "    ax5.set_ylabel('Frekuensi', fontweight='bold', fontsize=11)\n",
    "    ax5.set_title('⑤ Perbandingan Histogram', fontweight='bold', fontsize=13, pad=10)\n",
    "    ax5.legend(fontsize=10, loc='upper right')\n",
    "    ax5.grid(alpha=0.3, linestyle='--')\n",
    "    ax5.tick_params(labelsize=9)\n",
    "\n",
    "    # 6. Hasil Prediksi\n",
    "    ax6 = fig.add_subplot(gs[1, 2])\n",
    "    ax6.axis('off')\n",
    "\n",
    "    # Tentukan warna berdasarkan confidence\n",
    "    if confidence >= 0.9:\n",
    "        conf_color = '#27ae60'  # Hijau\n",
    "        conf_text = 'Sangat Tinggi'\n",
    "    elif confidence >= 0.7:\n",
    "        conf_color = '#f39c12'  # Orange\n",
    "        conf_text = 'Tinggi'\n",
    "    elif confidence >= 0.5:\n",
    "        conf_color = '#e67e22'  # Orange gelap\n",
    "        conf_text = 'Sedang'\n",
    "    else:\n",
    "        conf_color = '#e74c3c'  # Merah\n",
    "        conf_text = 'Rendah'\n",
    "\n",
    "    # Title prediksi\n",
    "    ax6.text(0.5, 0.95, '⑥ HASIL PREDIKSI', ha='center', va='top',\n",
    "            fontsize=13, fontweight='bold', transform=ax6.transAxes)\n",
    "\n",
    "    # Nama prediksi utama\n",
    "    display_name = pred_name[:25] + '...' if len(pred_name) > 25 else pred_name\n",
    "    ax6.text(0.5, 0.78, display_name, ha='center', va='center',\n",
    "            fontsize=15, fontweight='bold', color=conf_color,\n",
    "            transform=ax6.transAxes,\n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='white',\n",
    "                     edgecolor=conf_color, linewidth=2.5))\n",
    "\n",
    "    # Confidence score\n",
    "    ax6.text(0.5, 0.62, f'Confidence: {confidence*100:.2f}%',\n",
    "            ha='center', va='center',\n",
    "            fontsize=11, fontweight='bold', color=conf_color,\n",
    "            transform=ax6.transAxes)\n",
    "\n",
    "    ax6.text(0.5, 0.54, f'({conf_text})',\n",
    "            ha='center', va='center',\n",
    "            fontsize=10, style='italic', color=conf_color,\n",
    "            transform=ax6.transAxes)\n",
    "\n",
    "    # Top 3 predictions dalam box\n",
    "    y_start = 0.42\n",
    "    ax6.text(0.5, y_start, 'Top 3 Prediksi:', ha='center', va='center',\n",
    "            fontsize=10, fontweight='bold', transform=ax6.transAxes,\n",
    "            style='italic')\n",
    "\n",
    "    for i, (name, prob) in enumerate(zip(top_3_names, top_3_proba)):\n",
    "        display_n = name[:22] + '...' if len(name) > 22 else name\n",
    "        y_pos = y_start - 0.08 - (i * 0.1)\n",
    "\n",
    "        # Background untuk setiap prediksi\n",
    "        if i == 0:\n",
    "            bg_color = '#d5f4e6'  # Hijau muda untuk top 1\n",
    "            edge_color = '#27ae60'\n",
    "        else:\n",
    "            bg_color = '#f8f9fa'  # Abu-abu muda untuk lainnya\n",
    "            edge_color = '#bdc3c7'\n",
    "\n",
    "        ax6.text(0.15, y_pos, f'{i+1}. {display_n}',\n",
    "               ha='left', va='center', fontsize=9,\n",
    "               transform=ax6.transAxes,\n",
    "               bbox=dict(boxstyle='round,pad=0.3', facecolor=bg_color,\n",
    "                        edgecolor=edge_color, linewidth=1.5))\n",
    "        ax6.text(0.85, y_pos, f'{prob*100:.1f}%',\n",
    "               ha='right', va='center', fontsize=9, fontweight='bold',\n",
    "               transform=ax6.transAxes)\n",
    "\n",
    "    plt.suptitle('Pipeline Pengenalan Wajah', fontsize=16, fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "    # ========== RINGKASAN HASIL ==========\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RINGKASAN HASIL PENGENALAN\".center(70))\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nFile: {Path(image_path).name}\")\n",
    "    print(f\"\\n{'Identitas Terdeteksi:':<25} {pred_name}\")\n",
    "    print(f\"{'Confidence:':<25} {confidence*100:.2f}% ({conf_text})\")\n",
    "    print(f\"{'Class ID:':<25} {pred_id}\")\n",
    "\n",
    "    print(f\"\\n{'─'*70}\")\n",
    "    print(\"Top 3 Prediksi:\")\n",
    "    for i, (name, prob) in enumerate(zip(top_3_names, top_3_proba), 1):\n",
    "        print(f\"  {i}. {name[:45]:<45} {prob*100:.2f}%\")\n",
    "\n",
    "    print(f\"\\n{'─'*70}\")\n",
    "    print(\"Detail Teknis:\")\n",
    "    print(f\"  • Dimensi Fitur Asli: {feats.shape[1]} dimensi\")\n",
    "    print(f\"  • Dimensi Fitur PCA: {feats_pca.shape[1]} dimensi\")\n",
    "    print(f\"  • Reduksi Dimensi: {(1-feats_pca.shape[1]/feats.shape[1])*100:.1f}%\")\n",
    "    print(f\"  • PSNR: {psnr:.2f} dB\")\n",
    "    print(f\"  • MSE: {mse:.2f}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    # Simpan fitur ke file CSV\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "    # Save LBP features\n",
    "    np.savetxt(\n",
    "        f\"{base_name}_lbp.csv\",\n",
    "        feats.reshape(1, -1),\n",
    "        delimiter=\",\",\n",
    "        fmt=\"%.6f\"\n",
    "    )\n",
    "\n",
    "    # Save PCA features\n",
    "    np.savetxt(\n",
    "        f\"{base_name}_pca.csv\",\n",
    "        feats_pca.reshape(1, -1),\n",
    "        delimiter=\",\",\n",
    "        fmt=\"%.6f\"\n",
    "    )\n",
    "\n",
    "    print(f\"✓ Fitur telah disimpan:\")\n",
    "    print(f\"  • {base_name}_lbp.csv\")\n",
    "    print(f\"  • {base_name}_pca.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLhTkBuuNpJ0"
   },
   "source": [
    "## **[STAR] Main Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tOtOE2aPF1s"
   },
   "outputs": [],
   "source": [
    "def process_dataset(image_paths, labels):\n",
    "    \"\"\"\n",
    "    Memproses seluruh dataset melalui pipeline:\n",
    "    Face Detection → Preprocessing → Augmentasi\n",
    "\n",
    "    Parameter:\n",
    "        image_paths: List path ke semua gambar\n",
    "        labels: List label untuk setiap gambar\n",
    "\n",
    "    Return:\n",
    "        processed_images: List gambar yang telah diproses (termasuk augmentasi)\n",
    "        processed_labels: List label yang sesuai dengan gambar hasil augmentasi\n",
    "    \"\"\"\n",
    "    log(\"STEP 02 & 03: Face Detection → Preprocessing → Augmentasi\")\n",
    "\n",
    "    processed_images = []\n",
    "    processed_labels = []\n",
    "\n",
    "    for idx, image_path in enumerate(tqdm(image_paths, desc=\"Processing Dataset\")):\n",
    "        # --- TAHAP 1: Deteksi Wajah ---\n",
    "        eye_roi_image = face_detection_pipeline(image_path)\n",
    "        if eye_roi_image is None:\n",
    "            continue  # Skip jika gagal mendeteksi wajah\n",
    "\n",
    "        # --- TAHAP 2: Preprocessing ---\n",
    "        equalized_image = preprocessing_pipeline(eye_roi_image, target_size=CONFIG['EYE_ROI_TARGET_SIZE'])\n",
    "\n",
    "        # --- TAHAP 3: Augmentasi Data ---\n",
    "        # Menghasilkan beberapa variasi dari gambar untuk meningkatkan dataset\n",
    "        augmented = augmenting_pipeline(equalized_image)\n",
    "\n",
    "        # Simpan semua hasil augmentasi dengan label yang sama\n",
    "        label = labels[idx]\n",
    "        processed_images.extend(augmented)\n",
    "        processed_labels.extend([label] * len(augmented))\n",
    "\n",
    "    log(f\"✓ Selesai! Total {len(processed_images)} gambar berhasil diproses.\")\n",
    "    return processed_images, processed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQEQ4ZbrmoCI"
   },
   "outputs": [],
   "source": [
    "log(\"STEP 01: Loading Dataset\")\n",
    "image_paths, labels, label_to_id = load_dataset(CONFIG['DATASET_SOURCES'], CONFIG['USE_BOTH_SOURCES'], CONFIG['DATASET_LIMIT'])\n",
    "log(\"✓ Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GNbbNSafeVZi"
   },
   "outputs": [],
   "source": [
    "plot_class_distribution(labels, label_to_id, top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cC1mwy1tPNtb"
   },
   "outputs": [],
   "source": [
    "log(\"STEP 02 & 03: Processing Dataset\")\n",
    "processed_images, labels = process_dataset(image_paths, labels)\n",
    "log(\"✓ All Face Detection, Preprocessing, and Augmentation Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ol4u-JVpeYkW"
   },
   "outputs": [],
   "source": [
    "visualize_feature_samples(processed_images, labels, label_to_id, n_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s36wbVppnHuT"
   },
   "outputs": [],
   "source": [
    "log(\"STEP 04: Feature Extraction\")\n",
    "features = []\n",
    "for processed_image in tqdm(processed_images, desc=\"Extracting Features\"):\n",
    "    feature = feature_extraction_pipeline(processed_image)\n",
    "    features.append(feature)\n",
    "\n",
    "features = np.array(features)  # Convert to numpy array\n",
    "log(f\"✓ Done! Feature shape: {features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Di74UTlunOt0"
   },
   "outputs": [],
   "source": [
    "log(\"STEP 05: Classification\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "variance_explained = np.sum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Visualize dimensionality reduction\n",
    "plot_feature_dimensionality(X_train, X_train_pca, variance_explained)\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.figure(figsize=(16, 7))\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(range(1, len(cumsum) + 1), cumsum, 'b-o', linewidth=2, markersize=4)\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Variance')\n",
    "plt.xlabel('Number of Components', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Cumulative Explained Variance', fontsize=12, fontweight='bold')\n",
    "plt.title('PCA - Cumulative Explained Variance', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cross-validation on training set\n",
    "\n",
    "\n",
    "cv_scores = cross_validate_knn(X_train_pca, y_train, k=CONFIG['NEIGHBORS'], cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn = knn_fit(X_train_pca, y_train, k=CONFIG['NEIGHBORS'], metric='cosine', weights='distance')\n",
    "\n",
    "# Evaluate the model\n",
    "test_accuracy, y_pred = evaluate_knn(knn, X_test_pca, y_test, label_to_id)\n",
    "plot_confusion_matrix(y_test, y_pred, label_to_id, top_n=15)\n",
    "log(\"✓ Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_LGgLT53ROP"
   },
   "outputs": [],
   "source": [
    "# Save the trained model and label mapping\n",
    "log(\"Saving model and label mapping...\")\n",
    "\n",
    "model_data = {\n",
    "    'knn_model': knn,\n",
    "    'pca': pca,\n",
    "    'scaler': scaler,\n",
    "    'label_to_id': label_to_id,\n",
    "    'config': {\n",
    "        'k': CONFIG['NEIGHBORS'],\n",
    "        'metric': 'cosine',\n",
    "        'weights': 'distance',\n",
    "        'feature_dim_original': X_train.shape[1],\n",
    "        'feature_dim_pca': X_train_pca.shape[1],\n",
    "        'variance_explained': variance_explained,\n",
    "        'test_accuracy': test_accuracy\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(CONFIG['MODEL_PATH'] / 'knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "log(\"✓ Model saved successfully!\")\n",
    "log(f\"  File: {CONFIG['MODEL_PATH'] / 'knn_model.pkl'}\")\n",
    "log(f\"  Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_ksOO6S3fv7"
   },
   "outputs": [],
   "source": [
    "log(\"STEP 06: Inference\")\n",
    "\n",
    "image_test_path = \"esa_test.jpg\"\n",
    "\n",
    "log(f\"Processing test image: {image_test_path}\")\n",
    "inference_pipeline(image_test_path, knn, pca, scaler, label_to_id, CONFIG['EYE_ROI_TARGET_SIZE'])\n",
    "\n",
    "log(\"✓ Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **[STAR] Tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: Find Optimal K\n",
    "print(\"Running Experiment: Find Optimal K from 1 to 20\")\n",
    "k_results = find_optimal_k(X_train_pca, y_train, scaler, pca, label_to_id, 'test_images', k_range=range(1, 21))\n",
    "print(\"Optimal K:\", k_results['optimal_k'])\n",
    "print(\"Accuracy:\", k_results['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
